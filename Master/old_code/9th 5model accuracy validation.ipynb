{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "pd.set_option('display.max_columns', None)\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../DATA.csv', encoding='cp932')\n",
    "df=df.dropna(axis=0)\n",
    "\n",
    "y=df['EColi.']\n",
    "X=df.loc[:, ['up_down', 'curvature', 'inclination', 'tilt_direction', \n",
    "#              'altitude', 'source_ecoli',\n",
    "             'disto_river', 'disto_stations', \n",
    "             'disto_mainroad', 'disto_syorizyo', 'supply_hours', 'no_water_days', 'total_population ', 'population_served',\n",
    "             'popu-served', 'number_taps', 'pipelength', 'pipelength_per_pipe', 'served/pipes', '(popu-served)/pipes', \n",
    "             'oldest_pipe_age', 'ST', 'RSF', 'FL', 'PF', 'RF', 'ratio',  'nearest_source_E']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [ 95 115]\n",
      "Lables counts in y_train: [67 80]\n",
      "Lables counts in y_test: [28 35]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3,\n",
    "                                                  random_state=1, stratify=y)\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Lables counts in y_train:', np.bincount(y_train))\n",
    "print('Lables counts in y_test:', np.bincount(y_test))\n",
    "\n",
    "X_train_std=(X_train-X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "X_test_std=(X_test-X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "\n",
    "def threshold(fare):\n",
    "    if fare<=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "X_train_std['ST']=X_train_std['ST'].apply(threshold)\n",
    "X_train_std['RSF']=X_train_std['RSF'].apply(threshold)\n",
    "X_train_std['FL']=X_train_std['FL'].apply(threshold)\n",
    "X_train_std['PF']=X_train_std['PF'].apply(threshold)\n",
    "X_train_std['RF']=X_train_std['RF'].apply(threshold)\n",
    "X_test_std['ST']=X_test_std['ST'].apply(threshold)\n",
    "X_test_std['RSF']=X_test_std['RSF'].apply(threshold)\n",
    "X_test_std['FL']=X_test_std['FL'].apply(threshold)\n",
    "X_test_std['PF']=X_test_std['PF'].apply(threshold)\n",
    "X_test_std['RF']=X_test_std['RF'].apply(threshold)\n",
    "\n",
    "# 分割する\n",
    "X_cross=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "X_cross['ST']=X_cross['ST'].apply(threshold)\n",
    "X_cross['RSF']=X_cross['RSF'].apply(threshold)\n",
    "X_cross['FL']=X_cross['FL'].apply(threshold)\n",
    "X_cross['PF']=X_cross['PF'].apply(threshold)\n",
    "X_cross['RF']=X_cross['RF'].apply(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.673469387755102\n",
      "0.746031746031746\n",
      "0.470909090909091\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train_std, y_train)\n",
    "val=cross_val_score(estimator=clf, X=X_cross, y=y, cv=20)\n",
    "val1=np.mean(val)\n",
    "print(clf.score(X_train_std, y_train))\n",
    "print(clf.score(X_test_std, y_test))\n",
    "print(val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=0.0001, random_state=1), train: 0.544218, test: 0.555556, val: 0.547727\n",
      "params: LogisticRegression(C=0.001, random_state=1), train: 0.544218, test: 0.555556, val: 0.543182\n",
      "params: LogisticRegression(C=0.01, random_state=1), train: 0.557823, test: 0.571429, val: 0.569091\n",
      "params: LogisticRegression(C=0.1, random_state=1), train: 0.646259, test: 0.619048, val: 0.511364\n",
      "params: LogisticRegression(random_state=1), train: 0.598639, test: 0.587302, val: 0.496364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=10.0, random_state=1), train: 0.659864, test: 0.619048, val: 0.482273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=100.0, random_state=1), train: 0.680272, test: 0.650794, val: 0.477727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=1000.0, random_state=1), train: 0.666667, test: 0.666667, val: 0.487273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0\n",
    "SearchMethod = 0\n",
    "param_range=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(param_range)):\n",
    "    lr=LogisticRegression(C=param_range[i], random_state=1)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    score1 = lr.score(X_test_std, y_test)\n",
    "    score2 = lr.score(X_train_std, y_train)\n",
    "    dic[lr]=score1\n",
    "\n",
    "    if score1>max_score:\n",
    "        val=cross_val_score(estimator=lr, X=X_cross, y=y, cv=20)\n",
    "        val1=np.mean(val)\n",
    "        print('params: %s, train: %3f, test: %3f, val: %3f' %(lr, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "0.5578231292517006\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01, random_state=1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "score1 = lr.score(X_test_std, y_test)\n",
    "score2 = lr.score(X_train_std, y_train)\n",
    "print(score1)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b5568357f8e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscore1\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_cross\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mval1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params: %s, train: %3f, test: %3f, val: %3f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0;32m    161\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                        accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0\n",
    "SearchMethod = 0\n",
    "param_range=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "                                      \n",
    "dic={}\n",
    "for i in tqdm(range(len(param_range))):\n",
    "    svm=SVC(kernel='linear', C=param_range[i], random_state=1)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    score1 = svm.score(X_test_std, y_test)\n",
    "    score2 = svm.score(X_train_std, y_train)\n",
    "    dic[svm]=score1\n",
    "\n",
    "    if score1>max_score:\n",
    "        val=cross_val_score(estimator=svm, X=X_cross, y=y, cv=20)\n",
    "        val1=np.mean(val)\n",
    "        print('params: %s, train: %3f, test: %3f, val: %3f' %(svm, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "0.5578231292517006\n"
     ]
    }
   ],
   "source": [
    "svm=SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "score1 = lr.score(X_test_std, y_test)\n",
    "score2 = lr.score(X_train_std, y_train)\n",
    "print(score1)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0.71\n",
    "min_score=0.8\n",
    "SearchMethod = 0\n",
    "RFC_grid ={\"n_estimators\": [i for i in range(1, 51)],\n",
    "           \"criterion\": [\"gini\", \"entropy\"],\n",
    "           \"max_depth\":[i for i in range(1, 21)]\n",
    "          }\n",
    "           \n",
    "                                      \n",
    "dic={}\n",
    "for i in tqdm(range(len(RFC_grid['n_estimators']))):\n",
    "           for l in range(len(RFC_grid[\"criterion\"])):\n",
    "               for k in range(len(RFC_grid[\"max_depth\"])):\n",
    "                    forest=RandomForestClassifier(max_depth=RFC_grid[\"max_depth\"][k], criterion=RFC_grid[\"criterion\"][l], n_estimators=RFC_grid['n_estimators'][i], random_state=1)\n",
    "                    forest.fit(X_train_std, y_train)\n",
    "                    score1 = forest.score(X_test_std, y_test)\n",
    "                    score2 = forest.score(X_train_std, y_train)\n",
    "                    dic[forest]=score1\n",
    "\n",
    "                    if score1>max_score:\n",
    "                        if score2<min_score:\n",
    "                             val=cross_val_score(estimator=forest, X=X_cross, y=y, cv=20)\n",
    "                             val1=np.mean(val)\n",
    "                             print('params: %s, train: %3f, test: %3f, val: %3f' %(forest, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9863945578231292\n",
      "0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(max_depth=15, criterion='gini',n_estimators=13, random_state=1)\n",
    "forest.fit(X_train_std, y_train)\n",
    "print(forest.score(X_train_std, y_train))\n",
    "print(forest.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) no_water_days                  0.115566\n",
      " 2) popu-served                    0.091204\n",
      " 3) disto_river                    0.088918\n",
      " 4) inclination                    0.087825\n",
      " 5) disto_syorizyo                 0.073450\n",
      " 6) oldest_pipe_age                0.057143\n",
      " 7) served/pipes                   0.053577\n",
      " 8) supply_hours                   0.050573\n",
      " 9) tilt_direction                 0.050400\n",
      "10) pipelength_per_pipe            0.049986\n",
      "11) disto_mainroad                 0.039678\n",
      "12) (popu-served)/pipes            0.039042\n",
      "13) curvature                      0.038317\n",
      "14) ratio                          0.035618\n",
      "15) pipelength                     0.028821\n",
      "16) population_served              0.027062\n",
      "17) disto_stations                 0.022804\n",
      "18) nearest_source_E               0.018762\n",
      "19) number_taps                    0.017689\n",
      "20) total_population               0.009914\n",
      "21) up_down                        0.003651\n",
      "22) ST                             0.000000\n",
      "23) RSF                            0.000000\n",
      "24) FL                             0.000000\n",
      "25) PF                             0.000000\n",
      "26) RF                             0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels=X.columns[0:]\n",
    "forest=RandomForestClassifier(max_depth=3, criterion='entropy', n_estimators=29, random_state=1)\n",
    "forest.fit(X_train_std, y_train)\n",
    "importances=forest.feature_importances_\n",
    "indices=np.argsort(importances)[::-1]\n",
    "for f in range(X_train_std.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X_train.shape[1]), feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   n_estimators=18, random_state=1), train: 0.828947, test: 0.651515, val: 0.585909\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   n_estimators=21, random_state=1), train: 0.855263, test: 0.651515, val: 0.567273\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   n_estimators=22, random_state=1), train: 0.855263, test: 0.651515, val: 0.571818\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   n_estimators=23, random_state=1), train: 0.835526, test: 0.651515, val: 0.567273\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   n_estimators=24, random_state=1), train: 0.875000, test: 0.651515, val: 0.558182\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   learning_rate=1.5, n_estimators=3, random_state=1), train: 0.684211, test: 0.666667, val: 0.607273\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   learning_rate=1.5, n_estimators=4, random_state=1), train: 0.703947, test: 0.651515, val: 0.570909\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   learning_rate=1.5, n_estimators=5, random_state=1), train: 0.697368, test: 0.651515, val: 0.602727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                              | 1/20 [00:27<08:43, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   n_estimators=5, random_state=1), train: 0.815789, test: 0.651515, val: 0.551818\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=1.5, n_estimators=2, random_state=1), train: 0.697368, test: 0.666667, val: 0.552727\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=1.5, n_estimators=5, random_state=1), train: 0.822368, test: 0.651515, val: 0.539545\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=1.5, n_estimators=9, random_state=1), train: 0.888158, test: 0.651515, val: 0.525455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:47<07:35, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.5, n_estimators=2, random_state=1), train: 0.763158, test: 0.681818, val: 0.538636\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.5, n_estimators=3, random_state=1), train: 0.815789, test: 0.742424, val: 0.534091\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.5, n_estimators=4, random_state=1), train: 0.875000, test: 0.651515, val: 0.560909\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   n_estimators=2, random_state=1), train: 0.789474, test: 0.651515, val: 0.584091\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   n_estimators=3, random_state=1), train: 0.848684, test: 0.712121, val: 0.588182\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=1.5, n_estimators=4, random_state=1), train: 0.894737, test: 0.666667, val: 0.533182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [01:09<06:52, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
      "                   learning_rate=0.5, n_estimators=2, random_state=1), train: 0.842105, test: 0.712121, val: 0.492273\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
      "                   n_estimators=2, random_state=1), train: 0.861842, test: 0.681818, val: 0.501364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:16<00:00,  9.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0.65\n",
    "min_score=0.90\n",
    "SearchMethod = 0\n",
    "RFC_grid ={\"base_estimator\" : [DecisionTreeClassifier(max_depth=x) \n",
    "                                  for x in range(1, 21)],\n",
    "              \"learning_rate\" : [0.5, 1.0, 1.5],\n",
    "              \"n_estimators\": [i for i in range(1, 51)],\n",
    "           }   \n",
    "                                      \n",
    "dic={}\n",
    "for i in tqdm(range(len(RFC_grid['base_estimator']))):\n",
    "           for l in range(len(RFC_grid[\"learning_rate\"])):\n",
    "               for k in range(len(RFC_grid[\"n_estimators\"])):\n",
    "                    ada = AdaBoostClassifier(base_estimator=RFC_grid[\"base_estimator\"][i], learning_rate=RFC_grid[\"learning_rate\"][l], n_estimators=RFC_grid['n_estimators'][k], random_state=1)\n",
    "                    ada.fit(X_train_std, y_train)\n",
    "                    score1 = ada.score(X_test_std, y_test)\n",
    "                    score2 = ada.score(X_train_std, y_train)\n",
    "                    dic[ada]=score1\n",
    "\n",
    "                    if score1>max_score and 0.71:\n",
    "                        if score2<min_score :\n",
    "                             val=cross_val_score(estimator=ada, X=X_cross, y=y, cv=20)\n",
    "                             val1=np.mean(val)\n",
    "                             print('params: %s, train: %3f, test: %3f, val: %3f' %(ada, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_down</th>\n",
       "      <th>curvature</th>\n",
       "      <th>inclination</th>\n",
       "      <th>tilt_direction</th>\n",
       "      <th>altitude</th>\n",
       "      <th>disto_river</th>\n",
       "      <th>disto_stations</th>\n",
       "      <th>disto_mainroad</th>\n",
       "      <th>disto_syorizyo</th>\n",
       "      <th>supply_hours</th>\n",
       "      <th>no_water_days</th>\n",
       "      <th>total_population</th>\n",
       "      <th>population_served</th>\n",
       "      <th>popu-served</th>\n",
       "      <th>number_taps</th>\n",
       "      <th>pipelength</th>\n",
       "      <th>pipelength_per_pipe</th>\n",
       "      <th>served/pipes</th>\n",
       "      <th>(popu-served)/pipes</th>\n",
       "      <th>oldest_pipe_age</th>\n",
       "      <th>ST</th>\n",
       "      <th>RSF</th>\n",
       "      <th>FL</th>\n",
       "      <th>PF</th>\n",
       "      <th>RF</th>\n",
       "      <th>ratio</th>\n",
       "      <th>source_ecoli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-0.332556</td>\n",
       "      <td>0.048877</td>\n",
       "      <td>-0.499537</td>\n",
       "      <td>-1.132270</td>\n",
       "      <td>-0.261522</td>\n",
       "      <td>-1.270975</td>\n",
       "      <td>-0.134608</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>1.009180</td>\n",
       "      <td>-1.482984</td>\n",
       "      <td>-1.035729</td>\n",
       "      <td>-1.010099</td>\n",
       "      <td>-1.137692</td>\n",
       "      <td>-1.026670</td>\n",
       "      <td>-1.040723</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>-1.276738</td>\n",
       "      <td>-0.512732</td>\n",
       "      <td>-0.790003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084656</td>\n",
       "      <td>-1.272475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.208285</td>\n",
       "      <td>0.648968</td>\n",
       "      <td>0.083724</td>\n",
       "      <td>0.681555</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>-0.273641</td>\n",
       "      <td>0.942787</td>\n",
       "      <td>-0.399175</td>\n",
       "      <td>-0.262072</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>1.007989</td>\n",
       "      <td>1.005357</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.966378</td>\n",
       "      <td>-0.358239</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.722374</td>\n",
       "      <td>0.926867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-1.191389</td>\n",
       "      <td>0.084235</td>\n",
       "      <td>0.178151</td>\n",
       "      <td>0.901154</td>\n",
       "      <td>-0.545637</td>\n",
       "      <td>1.021978</td>\n",
       "      <td>-0.183867</td>\n",
       "      <td>-0.069734</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>1.007989</td>\n",
       "      <td>1.005357</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.966378</td>\n",
       "      <td>-0.358239</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.722374</td>\n",
       "      <td>0.926867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.867667</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.079805</td>\n",
       "      <td>1.322350</td>\n",
       "      <td>-1.160512</td>\n",
       "      <td>-0.509308</td>\n",
       "      <td>-0.972280</td>\n",
       "      <td>-0.357510</td>\n",
       "      <td>-0.403307</td>\n",
       "      <td>0.415263</td>\n",
       "      <td>-0.875454</td>\n",
       "      <td>-1.027813</td>\n",
       "      <td>-1.015769</td>\n",
       "      <td>-1.069916</td>\n",
       "      <td>-1.037307</td>\n",
       "      <td>-1.075525</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>-1.184980</td>\n",
       "      <td>0.936412</td>\n",
       "      <td>-1.097508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084656</td>\n",
       "      <td>-1.299058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-0.577936</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>0.131159</td>\n",
       "      <td>-1.165496</td>\n",
       "      <td>-0.447357</td>\n",
       "      <td>-0.957797</td>\n",
       "      <td>-0.110967</td>\n",
       "      <td>-0.434582</td>\n",
       "      <td>0.415263</td>\n",
       "      <td>-0.875454</td>\n",
       "      <td>-1.027813</td>\n",
       "      <td>-1.015769</td>\n",
       "      <td>-1.069916</td>\n",
       "      <td>-1.037307</td>\n",
       "      <td>-1.075525</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>-1.184980</td>\n",
       "      <td>0.936412</td>\n",
       "      <td>-1.097508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084656</td>\n",
       "      <td>-1.299058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-0.700627</td>\n",
       "      <td>0.072804</td>\n",
       "      <td>-0.018793</td>\n",
       "      <td>-0.949528</td>\n",
       "      <td>-0.386210</td>\n",
       "      <td>-0.255789</td>\n",
       "      <td>0.927290</td>\n",
       "      <td>0.060301</td>\n",
       "      <td>1.721881</td>\n",
       "      <td>-1.410819</td>\n",
       "      <td>-0.860701</td>\n",
       "      <td>-0.926974</td>\n",
       "      <td>-0.559035</td>\n",
       "      <td>-0.865303</td>\n",
       "      <td>-0.527228</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>-1.345752</td>\n",
       "      <td>-0.337213</td>\n",
       "      <td>-0.969381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084656</td>\n",
       "      <td>-1.162941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-0.577936</td>\n",
       "      <td>0.084042</td>\n",
       "      <td>-0.468957</td>\n",
       "      <td>0.934380</td>\n",
       "      <td>1.364782</td>\n",
       "      <td>1.120841</td>\n",
       "      <td>-0.307075</td>\n",
       "      <td>0.077573</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>1.007989</td>\n",
       "      <td>1.005357</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.966378</td>\n",
       "      <td>-0.358239</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.722374</td>\n",
       "      <td>0.926867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>0.280896</td>\n",
       "      <td>0.080655</td>\n",
       "      <td>-1.374168</td>\n",
       "      <td>-1.105690</td>\n",
       "      <td>-0.284091</td>\n",
       "      <td>-1.334650</td>\n",
       "      <td>-0.219071</td>\n",
       "      <td>-0.403644</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>-0.326663</td>\n",
       "      <td>-1.029285</td>\n",
       "      <td>-1.016018</td>\n",
       "      <td>-1.076769</td>\n",
       "      <td>-1.035238</td>\n",
       "      <td>-1.071279</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>-1.290515</td>\n",
       "      <td>0.612804</td>\n",
       "      <td>-0.969381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084656</td>\n",
       "      <td>-0.978781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.708742</td>\n",
       "      <td>-1.068698</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>0.917767</td>\n",
       "      <td>-0.479169</td>\n",
       "      <td>1.052911</td>\n",
       "      <td>0.145185</td>\n",
       "      <td>-0.073004</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>1.007989</td>\n",
       "      <td>1.005357</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.966378</td>\n",
       "      <td>-0.358239</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.722374</td>\n",
       "      <td>0.926867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.892416</td>\n",
       "      <td>1.998562</td>\n",
       "      <td>0.082644</td>\n",
       "      <td>0.866576</td>\n",
       "      <td>0.974251</td>\n",
       "      <td>0.041004</td>\n",
       "      <td>1.019634</td>\n",
       "      <td>-0.410704</td>\n",
       "      <td>-0.085569</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>1.007989</td>\n",
       "      <td>1.005357</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.966378</td>\n",
       "      <td>-0.358239</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.722374</td>\n",
       "      <td>0.926867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      up_down  curvature  inclination  tilt_direction  altitude  disto_river  \\\n",
       "216 -0.708742  -0.332556     0.048877       -0.499537 -1.132270    -0.261522   \n",
       "97   0.208285   0.648968     0.083724        0.681555  0.929396    -0.273641   \n",
       "148 -0.708742  -1.191389     0.084235        0.178151  0.901154    -0.545637   \n",
       "189  1.867667   0.035516     0.079805        1.322350 -1.160512    -0.509308   \n",
       "191 -0.708742  -0.577936     0.079543        0.131159 -1.165496    -0.447357   \n",
       "..        ...        ...          ...             ...       ...          ...   \n",
       "48  -0.708742  -0.700627     0.072804       -0.018793 -0.949528    -0.386210   \n",
       "153 -0.708742  -0.577936     0.084042       -0.468957  0.934380     1.364782   \n",
       "16  -0.708742   0.280896     0.080655       -1.374168 -1.105690    -0.284091   \n",
       "141 -0.708742  -1.068698     0.083286        0.042214  0.917767    -0.479169   \n",
       "121  0.892416   1.998562     0.082644        0.866576  0.974251     0.041004   \n",
       "\n",
       "     disto_stations  disto_mainroad  disto_syorizyo  supply_hours  \\\n",
       "216       -1.270975       -0.134608       -0.049270      1.009180   \n",
       "97         0.942787       -0.399175       -0.262072     -0.765937   \n",
       "148        1.021978       -0.183867       -0.069734     -0.765937   \n",
       "189       -0.972280       -0.357510       -0.403307      0.415263   \n",
       "191       -0.957797       -0.110967       -0.434582      0.415263   \n",
       "..              ...             ...             ...           ...   \n",
       "48        -0.255789        0.927290        0.060301      1.721881   \n",
       "153        1.120841       -0.307075        0.077573     -0.765937   \n",
       "16        -1.334650       -0.219071       -0.403644      0.058912   \n",
       "141        1.052911        0.145185       -0.073004     -0.765937   \n",
       "121        1.019634       -0.410704       -0.085569     -0.765937   \n",
       "\n",
       "     no_water_days  total_population   population_served  popu-served  \\\n",
       "216      -1.482984          -1.035729          -1.010099    -1.137692   \n",
       "97        0.502152           1.008618           1.009288     0.994830   \n",
       "148       0.502152           1.008618           1.009288     0.994830   \n",
       "189      -0.875454          -1.027813          -1.015769    -1.069916   \n",
       "191      -0.875454          -1.027813          -1.015769    -1.069916   \n",
       "..             ...                ...                ...          ...   \n",
       "48       -1.410819          -0.860701          -0.926974    -0.559035   \n",
       "153       0.502152           1.008618           1.009288     0.994830   \n",
       "16       -0.326663          -1.029285          -1.016018    -1.076769   \n",
       "141       0.502152           1.008618           1.009288     0.994830   \n",
       "121       0.502152           1.008618           1.009288     0.994830   \n",
       "\n",
       "     number_taps  pipelength  pipelength_per_pipe  served/pipes  \\\n",
       "216    -1.026670   -1.040723             0.019980     -1.276738   \n",
       "97      1.007989    1.005357            -0.174308      0.966378   \n",
       "148     1.007989    1.005357            -0.174308      0.966378   \n",
       "189    -1.037307   -1.075525             0.029677     -1.184980   \n",
       "191    -1.037307   -1.075525             0.029677     -1.184980   \n",
       "..           ...         ...                  ...           ...   \n",
       "48     -0.865303   -0.527228             0.006654     -1.345752   \n",
       "153     1.007989    1.005357            -0.174308      0.966378   \n",
       "16     -1.035238   -1.071279             0.005583     -1.290515   \n",
       "141     1.007989    1.005357            -0.174308      0.966378   \n",
       "121     1.007989    1.005357            -0.174308      0.966378   \n",
       "\n",
       "     (popu-served)/pipes  oldest_pipe_age  ST  RSF  FL  PF  RF     ratio  \\\n",
       "216            -0.512732        -0.790003   1    1   0   0   0  1.084656   \n",
       "97             -0.358239         1.003773   1    1   1   1   1 -0.722374   \n",
       "148            -0.358239         1.003773   1    1   1   1   1 -0.722374   \n",
       "189             0.936412        -1.097508   0    0   0   0   0  1.084656   \n",
       "191             0.936412        -1.097508   0    0   0   0   0  1.084656   \n",
       "..                   ...              ...  ..  ...  ..  ..  ..       ...   \n",
       "48             -0.337213        -0.969381   0    0   0   0   0  1.084656   \n",
       "153            -0.358239         1.003773   1    1   1   1   1 -0.722374   \n",
       "16              0.612804        -0.969381   0    0   0   0   0  1.084656   \n",
       "141            -0.358239         1.003773   1    1   1   1   1 -0.722374   \n",
       "121            -0.358239         1.003773   1    1   1   1   1 -0.722374   \n",
       "\n",
       "     source_ecoli  \n",
       "216     -1.272475  \n",
       "97       0.926867  \n",
       "148      0.926867  \n",
       "189     -1.299058  \n",
       "191     -1.299058  \n",
       "..            ...  \n",
       "48      -1.162941  \n",
       "153      0.926867  \n",
       "16      -0.978781  \n",
       "141      0.926867  \n",
       "121      0.926867  \n",
       "\n",
       "[152 rows x 27 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
