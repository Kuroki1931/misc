{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('DATA.csv')\n",
    "df=df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['EColi.']\n",
    "X=df.loc[:, ['up_down', 'curvature', 'inclination', 'tilt_direction', 'altitude', 'disto_river', 'disto_stations', \n",
    "             'disto_mainroad', 'disto_syorizyo', 'supply_hours', 'no_water_days', 'total_population ', 'population_served',\n",
    "             'popu-served', 'number_taps', 'pipelength', 'pipelength_per_pipe', 'served/pipes', '(popu-served)/pipes', \n",
    "             'oldest_pipe_age', 'ST', 'RSF', 'FL', 'PF', 'RF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['EColi.']\n",
    "X=df.loc[:, ['up_down', 'curvature', 'inclination', 'tilt_direction', 'altitude', 'disto_river', 'disto_stations', \n",
    "             'disto_mainroad', 'disto_syorizyo', 'supply_hours', 'no_water_days', 'total_population ', 'population_served',\n",
    "             'popu-served', 'number_taps', 'pipelength',  \n",
    "             'oldest_pipe_age', 'ST', 'RSF', 'FL', 'PF', 'RF', 'ratio', 'source_ecoli']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['EColi.']\n",
    "X=df.loc[:, ['up_down', 'curvature', 'inclination', 'tilt_direction', 'altitude', 'disto_river', 'disto_stations', \n",
    "             'disto_mainroad', 'disto_syorizyo', 'supply_hours', 'no_water_days', 'total_population ', 'population_served',\n",
    "             'popu-served', 'number_taps', 'pipelength', 'pipelength_per_pipe', 'served/pipes', '(popu-served)/pipes', \n",
    "             'oldest_pipe_age', 'ST', 'RSF', 'FL', 'PF', 'RF', 'ratio', 'source_ecoli']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['EColi.']\n",
    "X=df.loc[:, ['up_down', 'curvature', 'inclination', 'tilt_direction', 'altitude', 'disto_river', 'disto_stations', \n",
    "             'disto_mainroad', 'disto_syorizyo', 'supply_hours', 'no_water_days', 'total_population ', 'population_served',\n",
    "             'popu-served', 'number_taps', 'pipelength', 'pipelength_per_pipe', 'served/pipes', '(popu-served)/pipes', \n",
    "             'oldest_pipe_age', 'ST', 'RSF', 'FL', 'PF', 'RF', 'ratio', 'source_ecoli']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [ 98 120]\n",
      "Lables counts in y_train: [68 84]\n",
      "Lables counts in y_test: [30 36]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3,\n",
    "                                                  random_state=1, stratify=y)\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Lables counts in y_train:', np.bincount(y_train))\n",
    "print('Lables counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std=(X_train-X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "X_test_std=(X_test-X_train.mean(axis=0))/X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(fare):\n",
    "    if fare<=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std['ST']=X_train_std['ST'].apply(threshold)\n",
    "X_train_std['RSF']=X_train_std['RSF'].apply(threshold)\n",
    "X_train_std['FL']=X_train_std['FL'].apply(threshold)\n",
    "X_train_std['PF']=X_train_std['PF'].apply(threshold)\n",
    "X_train_std['RF']=X_train_std['RF'].apply(threshold)\n",
    "X_test_std['ST']=X_test_std['ST'].apply(threshold)\n",
    "X_test_std['RSF']=X_test_std['RSF'].apply(threshold)\n",
    "X_test_std['FL']=X_test_std['FL'].apply(threshold)\n",
    "X_test_std['PF']=X_test_std['PF'].apply(threshold)\n",
    "X_test_std['RF']=X_test_std['RF'].apply(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: SVC(C=0.0001, kernel='linear', random_state=1), train: 0.552632, test: 0.545455, val: 0.552680\n",
      "params: SVC(C=0.001, kernel='linear', random_state=1), train: 0.552632, test: 0.545455, val: 0.552680\n",
      "params: SVC(C=0.01, kernel='linear', random_state=1), train: 0.585526, test: 0.560606, val: 0.559216\n",
      "params: SVC(C=0.1, kernel='linear', random_state=1), train: 0.644737, test: 0.606061, val: 0.605621\n",
      "params: SVC(kernel='linear', random_state=1), train: 0.684211, test: 0.681818, val: 0.573203\n",
      "params: SVC(C=10.0, kernel='linear', random_state=1), train: 0.690789, test: 0.681818, val: 0.539739\n",
      "params: SVC(C=100.0, kernel='linear', random_state=1), train: 0.697368, test: 0.575758, val: 0.566536\n",
      "params: SVC(C=1000.0, kernel='linear', random_state=1), train: 0.690789, test: 0.606061, val: 0.559869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0\n",
    "SearchMethod = 0\n",
    "param_range=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(param_range)):\n",
    "    svm=SVC(kernel='linear', C=param_range[i], random_state=1)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    score1 = svm.score(X_test_std, y_test)\n",
    "    score2 = svm.score(X_train_std, y_train)\n",
    "    dic[svm]=score1\n",
    "\n",
    "    if score1>max_score:\n",
    "        val=cross_val_score(estimator=svm, X=X_train_std, y=y_train, cv=3)\n",
    "        val1=np.mean(val)\n",
    "        print('params: %s, train: %3f, test: %3f, val: %3f' %(svm, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=0.0001, random_state=1), train: 0.552632, test: 0.545455, val: 0.552680\n",
      "params: LogisticRegression(C=0.001, random_state=1), train: 0.552632, test: 0.530303, val: 0.552680\n",
      "params: LogisticRegression(C=0.01, random_state=1), train: 0.611842, test: 0.560606, val: 0.572418\n",
      "params: LogisticRegression(C=0.1, random_state=1), train: 0.638158, test: 0.575758, val: 0.592418\n",
      "params: LogisticRegression(random_state=1), train: 0.690789, test: 0.560606, val: 0.572680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: LogisticRegression(C=10.0, random_state=1), train: 0.690789, test: 0.636364, val: 0.500915\n",
      "params: LogisticRegression(C=100.0, random_state=1), train: 0.703947, test: 0.696970, val: 0.527190\n",
      "params: LogisticRegression(C=1000.0, random_state=1), train: 0.717105, test: 0.696970, val: 0.540392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\kurokiso\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0\n",
    "SearchMethod = 0\n",
    "param_range=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(param_range)):\n",
    "    lr=LogisticRegression(C=param_range[i], random_state=1)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    score1 = lr.score(X_test_std, y_test)\n",
    "    score2 = lr.score(X_train_std, y_train)\n",
    "    dic[lr]=score1\n",
    "\n",
    "    if score1>max_score:\n",
    "        val=cross_val_score(estimator=lr, X=X_train_std, y=y_train, cv=3)\n",
    "        val1=np.mean(val)\n",
    "        print('params: %s, train: %3f, test: %3f, val: %3f' %(lr, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: RandomForestClassifier(max_depth=8, n_estimators=12, random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(max_depth=10, n_estimators=12, random_state=1), score: 0.727273, val: 0.533856\n",
      "params: RandomForestClassifier(max_depth=10, n_estimators=13, random_state=1), score: 0.712121, val: 0.533987\n",
      "params: RandomForestClassifier(max_depth=11, n_estimators=13, random_state=1), score: 0.712121, val: 0.553725\n",
      "params: RandomForestClassifier(max_depth=12, n_estimators=13, random_state=1), score: 0.727273, val: 0.540523\n",
      "params: RandomForestClassifier(max_depth=8, n_estimators=14, random_state=1), score: 0.712121, val: 0.546797\n",
      "params: RandomForestClassifier(max_depth=12, n_estimators=19, random_state=1), score: 0.712121, val: 0.533725\n",
      "params: RandomForestClassifier(max_depth=13, n_estimators=19, random_state=1), score: 0.712121, val: 0.520523\n",
      "params: RandomForestClassifier(max_depth=7, n_estimators=20, random_state=1), score: 0.712121, val: 0.540392\n",
      "params: RandomForestClassifier(max_depth=13, n_estimators=20, random_state=1), score: 0.712121, val: 0.533856\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=20,\n",
      "                       random_state=1), score: 0.712121, val: 0.526928\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=17, n_estimators=20,\n",
      "                       random_state=1), score: 0.712121, val: 0.526928\n",
      "params: RandomForestClassifier(max_depth=9, n_estimators=21, random_state=1), score: 0.712121, val: 0.513595\n",
      "params: RandomForestClassifier(max_depth=12, n_estimators=21, random_state=1), score: 0.727273, val: 0.546797\n",
      "params: RandomForestClassifier(max_depth=13, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=14, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=15, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=16, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=17, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=18, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=19, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(max_depth=20, n_estimators=21, random_state=1), score: 0.712121, val: 0.520392\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=21,\n",
      "                       random_state=1), score: 0.712121, val: 0.527059\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=21,\n",
      "                       random_state=1), score: 0.712121, val: 0.533595\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=17, n_estimators=21,\n",
      "                       random_state=1), score: 0.712121, val: 0.533595\n",
      "params: RandomForestClassifier(max_depth=9, n_estimators=22, random_state=1), score: 0.727273, val: 0.474118\n",
      "params: RandomForestClassifier(max_depth=13, n_estimators=22, random_state=1), score: 0.727273, val: 0.527190\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=22,\n",
      "                       random_state=1), score: 0.712121, val: 0.527190\n",
      "params: RandomForestClassifier(max_depth=7, n_estimators=23, random_state=1), score: 0.712121, val: 0.514118\n",
      "params: RandomForestClassifier(max_depth=12, n_estimators=23, random_state=1), score: 0.712121, val: 0.520654\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=23,\n",
      "                       random_state=1), score: 0.712121, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=23,\n",
      "                       random_state=1), score: 0.757576, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=23,\n",
      "                       random_state=1), score: 0.712121, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=16, n_estimators=23,\n",
      "                       random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=17, n_estimators=23,\n",
      "                       random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=18, n_estimators=23,\n",
      "                       random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=19, n_estimators=23,\n",
      "                       random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=23,\n",
      "                       random_state=1), score: 0.727273, val: 0.540261\n",
      "params: RandomForestClassifier(max_depth=9, n_estimators=24, random_state=1), score: 0.712121, val: 0.487451\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=24,\n",
      "                       random_state=1), score: 0.712121, val: 0.533595\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=24,\n",
      "                       random_state=1), score: 0.727273, val: 0.566405\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=24,\n",
      "                       random_state=1), score: 0.712121, val: 0.566405\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=16, n_estimators=24,\n",
      "                       random_state=1), score: 0.727273, val: 0.573072\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=25,\n",
      "                       random_state=1), score: 0.712121, val: 0.546928\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=25,\n",
      "                       random_state=1), score: 0.727273, val: 0.540131\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=25,\n",
      "                       random_state=1), score: 0.727273, val: 0.533464\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=16, n_estimators=25,\n",
      "                       random_state=1), score: 0.727273, val: 0.546797\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=17, n_estimators=25,\n",
      "                       random_state=1), score: 0.712121, val: 0.546797\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=26,\n",
      "                       random_state=1), score: 0.712121, val: 0.533464\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=26,\n",
      "                       random_state=1), score: 0.712121, val: 0.559869\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=3, n_estimators=27,\n",
      "                       random_state=1), score: 0.712121, val: 0.533464\n",
      "params: RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=27,\n",
      "                       random_state=1), score: 0.712121, val: 0.540392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8318ac1ae6d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mforest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRFC_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRFC_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"criterion\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRFC_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     \u001b[0mscore1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                     \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    684\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[0;32m    685\u001b[0m                                             lock)\n\u001b[1;32m--> 686\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \"\"\"\n\u001b[1;32m--> 466\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0.70\n",
    "SearchMethod = 0\n",
    "RFC_grid ={\"n_estimators\": [i for i in range(1, 51)],\n",
    "           \"criterion\": [\"gini\", \"entropy\"],\n",
    "           \"max_depth\":[i for i in range(1, 21)]\n",
    "          }\n",
    "           \n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(RFC_grid['n_estimators'])):\n",
    "           for l in range(len(RFC_grid[\"criterion\"])):\n",
    "               for k in range(len(RFC_grid[\"max_depth\"])):\n",
    "                    forest=RandomForestClassifier(max_depth=RFC_grid[\"max_depth\"][k], criterion=RFC_grid[\"criterion\"][l], n_estimators=RFC_grid['n_estimators'][i], random_state=1)\n",
    "                    forest.fit(X_train_std, y_train)\n",
    "                    score1 = forest.score(X_test_std, y_test)\n",
    "                    dic[forest]=score1\n",
    "\n",
    "                    if score1>max_score:\n",
    "                        val=cross_val_score(estimator=forest,\n",
    "                                            X=X_train_std, y=y_train, cv=3)\n",
    "                        val1=np.mean(val)\n",
    "                        print('params: %s, score: %3f, val: %3f' %(forest, score1, val1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=23,\n",
      "                       random_state=1), train: 1.000000, test: 0.757576, val: 0.540261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0.75\n",
    "SearchMethod = 0\n",
    "RFC_grid ={\"n_estimators\": [i for i in range(1, 51)],\n",
    "           \"criterion\": [\"gini\", \"entropy\"],\n",
    "           \"max_depth\":[i for i in range(1, 21)]\n",
    "          }\n",
    "           \n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(RFC_grid['n_estimators'])):\n",
    "           for l in range(len(RFC_grid[\"criterion\"])):\n",
    "               for k in range(len(RFC_grid[\"max_depth\"])):\n",
    "                    forest=RandomForestClassifier(max_depth=RFC_grid[\"max_depth\"][k], criterion=RFC_grid[\"criterion\"][l], n_estimators=RFC_grid['n_estimators'][i], random_state=1)\n",
    "                    forest.fit(X_train_std, y_train)\n",
    "                    score1 = forest.score(X_test_std, y_test)\n",
    "                    score2 = forest.score(X_train_std, y_train)\n",
    "                    dic[forest]=score1\n",
    "\n",
    "                    if score1>max_score:\n",
    "                        val=cross_val_score(estimator=forest,\n",
    "                                            X=X_train_std, y=y_train,\n",
    "                                            cv=3)\n",
    "                        val1=np.mean(val)\n",
    "                        print('params: %s, train: %3f, test: %3f, val: %3f' %(forest, score2, score1, val1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=7, random_state=1), train: 1.000000, test: 0.666667, val: 0.526536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=14, random_state=1), train: 1.000000, test: 0.651515, val: 0.546536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=17, random_state=1), train: 1.000000, test: 0.651515, val: 0.540000\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=18, random_state=1), train: 1.000000, test: 0.651515, val: 0.559869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=22, random_state=1), train: 1.000000, test: 0.651515, val: 0.519869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=23, random_state=1), train: 1.000000, test: 0.651515, val: 0.539608\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=25, random_state=1), train: 1.000000, test: 0.666667, val: 0.572549\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=42, random_state=1), train: 1.000000, test: 0.651515, val: 0.527059\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=43, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=44, random_state=1), train: 1.000000, test: 0.681818, val: 0.527190\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=45, random_state=1), train: 1.000000, test: 0.666667, val: 0.527190\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=46, random_state=1), train: 1.000000, test: 0.666667, val: 0.540392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=47, random_state=1), train: 1.000000, test: 0.681818, val: 0.533856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=48, random_state=1), train: 1.000000, test: 0.666667, val: 0.540392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=49, random_state=1), train: 1.000000, test: 0.651515, val: 0.533725\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   random_state=1), train: 1.000000, test: 0.651515, val: 0.533725\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=51, random_state=1), train: 1.000000, test: 0.666667, val: 0.527190\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=52, random_state=1), train: 1.000000, test: 0.666667, val: 0.540261\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=53, random_state=1), train: 1.000000, test: 0.651515, val: 0.553595\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=54, random_state=1), train: 1.000000, test: 0.651515, val: 0.540261\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=55, random_state=1), train: 1.000000, test: 0.666667, val: 0.546928\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=56, random_state=1), train: 1.000000, test: 0.651515, val: 0.540392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=59, random_state=1), train: 1.000000, test: 0.651515, val: 0.540392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=60, random_state=1), train: 1.000000, test: 0.651515, val: 0.540392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=61, random_state=1), train: 1.000000, test: 0.651515, val: 0.533856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=79, random_state=1), train: 1.000000, test: 0.651515, val: 0.533856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=82, random_state=1), train: 1.000000, test: 0.651515, val: 0.533725\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=87, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=92, random_state=1), train: 1.000000, test: 0.651515, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=93, random_state=1), train: 1.000000, test: 0.651515, val: 0.520392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=94, random_state=1), train: 1.000000, test: 0.666667, val: 0.520392\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=98, random_state=1), train: 1.000000, test: 0.651515, val: 0.540261\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   n_estimators=99, random_state=1), train: 1.000000, test: 0.651515, val: 0.540131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=6, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=9, random_state=1), train: 1.000000, test: 0.651515, val: 0.520523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=10, random_state=1), train: 1.000000, test: 0.651515, val: 0.526928\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=21, random_state=1), train: 1.000000, test: 0.681818, val: 0.494248\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=28, random_state=1), train: 1.000000, test: 0.651515, val: 0.533987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=29, random_state=1), train: 1.000000, test: 0.666667, val: 0.540523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=32, random_state=1), train: 1.000000, test: 0.651515, val: 0.527451\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=41, random_state=1), train: 1.000000, test: 0.651515, val: 0.521046\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=64, random_state=1), train: 1.000000, test: 0.651515, val: 0.520915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=73, random_state=1), train: 1.000000, test: 0.651515, val: 0.553464\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=77, random_state=1), train: 1.000000, test: 0.651515, val: 0.540523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                   learning_rate=1.5, n_estimators=82, random_state=1), train: 1.000000, test: 0.651515, val: 0.527451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=38, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=46, random_state=1), train: 1.000000, test: 0.651515, val: 0.553072\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=47, random_state=1), train: 1.000000, test: 0.651515, val: 0.546536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=48, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=51, random_state=1), train: 1.000000, test: 0.666667, val: 0.546405\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=52, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=53, random_state=1), train: 1.000000, test: 0.651515, val: 0.533333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=54, random_state=1), train: 1.000000, test: 0.651515, val: 0.533333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=55, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=57, random_state=1), train: 1.000000, test: 0.666667, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=60, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=61, random_state=1), train: 1.000000, test: 0.666667, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=62, random_state=1), train: 1.000000, test: 0.651515, val: 0.546405\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=63, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=64, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=65, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=66, random_state=1), train: 1.000000, test: 0.666667, val: 0.559477\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=67, random_state=1), train: 1.000000, test: 0.651515, val: 0.552810\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=68, random_state=1), train: 1.000000, test: 0.651515, val: 0.552810\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=69, random_state=1), train: 1.000000, test: 0.651515, val: 0.552810\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=70, random_state=1), train: 1.000000, test: 0.651515, val: 0.559477\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=71, random_state=1), train: 1.000000, test: 0.666667, val: 0.552810\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=72, random_state=1), train: 1.000000, test: 0.666667, val: 0.546275\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=73, random_state=1), train: 1.000000, test: 0.666667, val: 0.539739\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=74, random_state=1), train: 1.000000, test: 0.651515, val: 0.546405\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=75, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=76, random_state=1), train: 1.000000, test: 0.666667, val: 0.559477\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=77, random_state=1), train: 1.000000, test: 0.651515, val: 0.552941\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=78, random_state=1), train: 1.000000, test: 0.651515, val: 0.539739\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=79, random_state=1), train: 1.000000, test: 0.651515, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=80, random_state=1), train: 1.000000, test: 0.651515, val: 0.546536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=81, random_state=1), train: 1.000000, test: 0.681818, val: 0.559477\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=82, random_state=1), train: 1.000000, test: 0.681818, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=83, random_state=1), train: 1.000000, test: 0.681818, val: 0.546405\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=84, random_state=1), train: 1.000000, test: 0.666667, val: 0.539739\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=85, random_state=1), train: 1.000000, test: 0.651515, val: 0.533203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=86, random_state=1), train: 1.000000, test: 0.666667, val: 0.533203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=87, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=88, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=89, random_state=1), train: 1.000000, test: 0.666667, val: 0.533333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=90, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=91, random_state=1), train: 1.000000, test: 0.666667, val: 0.520131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=92, random_state=1), train: 1.000000, test: 0.666667, val: 0.526667\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=93, random_state=1), train: 1.000000, test: 0.666667, val: 0.520131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=94, random_state=1), train: 1.000000, test: 0.651515, val: 0.520131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=95, random_state=1), train: 1.000000, test: 0.666667, val: 0.520131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=96, random_state=1), train: 1.000000, test: 0.651515, val: 0.526667\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=97, random_state=1), train: 1.000000, test: 0.666667, val: 0.533203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=98, random_state=1), train: 1.000000, test: 0.651515, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=0.5, n_estimators=99, random_state=1), train: 1.000000, test: 0.666667, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=9, random_state=1), train: 1.000000, test: 0.666667, val: 0.474248\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=24, random_state=1), train: 1.000000, test: 0.651515, val: 0.573203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=25, random_state=1), train: 1.000000, test: 0.651515, val: 0.559869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=26, random_state=1), train: 1.000000, test: 0.681818, val: 0.559869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=27, random_state=1), train: 1.000000, test: 0.666667, val: 0.540131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=28, random_state=1), train: 1.000000, test: 0.666667, val: 0.553333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=31, random_state=1), train: 1.000000, test: 0.651515, val: 0.566797\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=37, random_state=1), train: 1.000000, test: 0.651515, val: 0.553725\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=58, random_state=1), train: 1.000000, test: 0.651515, val: 0.560131\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=59, random_state=1), train: 1.000000, test: 0.666667, val: 0.546928\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=60, random_state=1), train: 1.000000, test: 0.666667, val: 0.553595\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=61, random_state=1), train: 1.000000, test: 0.666667, val: 0.553595\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=62, random_state=1), train: 1.000000, test: 0.651515, val: 0.566797\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=63, random_state=1), train: 1.000000, test: 0.666667, val: 0.573333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=64, random_state=1), train: 1.000000, test: 0.666667, val: 0.566797\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=65, random_state=1), train: 1.000000, test: 0.666667, val: 0.580000\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=66, random_state=1), train: 1.000000, test: 0.666667, val: 0.580000\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=67, random_state=1), train: 1.000000, test: 0.651515, val: 0.573333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=68, random_state=1), train: 1.000000, test: 0.666667, val: 0.560000\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=69, random_state=1), train: 1.000000, test: 0.651515, val: 0.573203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=70, random_state=1), train: 1.000000, test: 0.651515, val: 0.560000\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=73, random_state=1), train: 1.000000, test: 0.651515, val: 0.573333\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=75, random_state=1), train: 1.000000, test: 0.666667, val: 0.566536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=86, random_state=1), train: 1.000000, test: 0.651515, val: 0.553203\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=89, random_state=1), train: 1.000000, test: 0.651515, val: 0.546536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=91, random_state=1), train: 1.000000, test: 0.651515, val: 0.546536\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   n_estimators=92, random_state=1), train: 1.000000, test: 0.651515, val: 0.539869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=13, random_state=1), train: 1.000000, test: 0.651515, val: 0.552810\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=16, random_state=1), train: 1.000000, test: 0.651515, val: 0.566275\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=17, random_state=1), train: 1.000000, test: 0.651515, val: 0.526667\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=18, random_state=1), train: 1.000000, test: 0.681818, val: 0.559869\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=20, random_state=1), train: 1.000000, test: 0.666667, val: 0.553072\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=22, random_state=1), train: 1.000000, test: 0.651515, val: 0.539739\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=91, random_state=1), train: 1.000000, test: 0.651515, val: 0.507843\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=93, random_state=1), train: 1.000000, test: 0.651515, val: 0.494510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=94, random_state=1), train: 1.000000, test: 0.651515, val: 0.507582\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=95, random_state=1), train: 1.000000, test: 0.651515, val: 0.487843\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=96, random_state=1), train: 1.000000, test: 0.651515, val: 0.487843\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=97, random_state=1), train: 1.000000, test: 0.651515, val: 0.487843\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=98, random_state=1), train: 1.000000, test: 0.651515, val: 0.494379\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                   learning_rate=1.5, n_estimators=99, random_state=1), train: 1.000000, test: 0.651515, val: 0.487712\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=0.5, n_estimators=4, random_state=1), train: 1.000000, test: 0.651515, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=58, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=70, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=74, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=79, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=80, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=82, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=93, random_state=1), train: 1.000000, test: 0.681818, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=94, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=96, random_state=1), train: 1.000000, test: 0.651515, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=97, random_state=1), train: 1.000000, test: 0.666667, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=98, random_state=1), train: 1.000000, test: 0.666667, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   n_estimators=99, random_state=1), train: 1.000000, test: 0.666667, val: 0.480915\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=20, random_state=1), train: 1.000000, test: 0.651515, val: 0.520654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=22, random_state=1), train: 1.000000, test: 0.651515, val: 0.540523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=24, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=26, random_state=1), train: 1.000000, test: 0.712121, val: 0.527320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=27, random_state=1), train: 1.000000, test: 0.651515, val: 0.520654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=28, random_state=1), train: 1.000000, test: 0.696970, val: 0.494248\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=29, random_state=1), train: 1.000000, test: 0.681818, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=30, random_state=1), train: 1.000000, test: 0.681818, val: 0.494118\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=31, random_state=1), train: 1.000000, test: 0.696970, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=32, random_state=1), train: 1.000000, test: 0.681818, val: 0.494118\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=33, random_state=1), train: 1.000000, test: 0.696970, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=34, random_state=1), train: 1.000000, test: 0.696970, val: 0.494118\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=35, random_state=1), train: 1.000000, test: 0.712121, val: 0.494248\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=36, random_state=1), train: 1.000000, test: 0.681818, val: 0.507451\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=37, random_state=1), train: 1.000000, test: 0.696970, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=38, random_state=1), train: 1.000000, test: 0.681818, val: 0.507451\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=39, random_state=1), train: 1.000000, test: 0.666667, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=40, random_state=1), train: 1.000000, test: 0.666667, val: 0.507451\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=41, random_state=1), train: 1.000000, test: 0.666667, val: 0.520654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=46, random_state=1), train: 1.000000, test: 0.666667, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=48, random_state=1), train: 1.000000, test: 0.651515, val: 0.500523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=49, random_state=1), train: 1.000000, test: 0.651515, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, random_state=1), train: 1.000000, test: 0.651515, val: 0.507190\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=57, random_state=1), train: 1.000000, test: 0.651515, val: 0.520392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=58, random_state=1), train: 1.000000, test: 0.651515, val: 0.527059\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=59, random_state=1), train: 1.000000, test: 0.681818, val: 0.533725\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=60, random_state=1), train: 1.000000, test: 0.681818, val: 0.527059\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=61, random_state=1), train: 1.000000, test: 0.666667, val: 0.520523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=62, random_state=1), train: 1.000000, test: 0.666667, val: 0.520523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=63, random_state=1), train: 1.000000, test: 0.681818, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=64, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=65, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=67, random_state=1), train: 1.000000, test: 0.666667, val: 0.507190\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=68, random_state=1), train: 1.000000, test: 0.666667, val: 0.520523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=69, random_state=1), train: 1.000000, test: 0.666667, val: 0.520523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=70, random_state=1), train: 1.000000, test: 0.681818, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=71, random_state=1), train: 1.000000, test: 0.666667, val: 0.520654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=72, random_state=1), train: 1.000000, test: 0.651515, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=73, random_state=1), train: 1.000000, test: 0.666667, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=74, random_state=1), train: 1.000000, test: 0.666667, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=75, random_state=1), train: 1.000000, test: 0.696970, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=76, random_state=1), train: 1.000000, test: 0.666667, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=77, random_state=1), train: 1.000000, test: 0.666667, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=78, random_state=1), train: 1.000000, test: 0.666667, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=79, random_state=1), train: 1.000000, test: 0.666667, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=80, random_state=1), train: 1.000000, test: 0.666667, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=81, random_state=1), train: 1.000000, test: 0.681818, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=82, random_state=1), train: 1.000000, test: 0.666667, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=83, random_state=1), train: 1.000000, test: 0.681818, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=84, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=85, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=86, random_state=1), train: 1.000000, test: 0.681818, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=87, random_state=1), train: 1.000000, test: 0.651515, val: 0.520654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=88, random_state=1), train: 1.000000, test: 0.651515, val: 0.493987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=89, random_state=1), train: 1.000000, test: 0.651515, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=90, random_state=1), train: 1.000000, test: 0.651515, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=91, random_state=1), train: 1.000000, test: 0.681818, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=92, random_state=1), train: 1.000000, test: 0.681818, val: 0.500654\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=93, random_state=1), train: 1.000000, test: 0.681818, val: 0.507320\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=94, random_state=1), train: 1.000000, test: 0.681818, val: 0.513987\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=95, random_state=1), train: 1.000000, test: 0.651515, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=96, random_state=1), train: 1.000000, test: 0.666667, val: 0.500523\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=97, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=98, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n",
      "params: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7),\n",
      "                   learning_rate=1.5, n_estimators=99, random_state=1), train: 1.000000, test: 0.666667, val: 0.513856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_score =0.65\n",
    "SearchMethod = 0\n",
    "RFC_grid ={\"base_estimator\" : [DecisionTreeClassifier(max_depth=x) \n",
    "                                  for x in range(5, 10)],\n",
    "              \"learning_rate\" : [0.5, 1.0, 1.5],\n",
    "              \"n_estimators\": [i for i in range(1, 100)],\n",
    "           }   \n",
    "                                      \n",
    "dic={}\n",
    "for i in range(len(RFC_grid['base_estimator'])):\n",
    "           for l in range(len(RFC_grid[\"learning_rate\"])):\n",
    "               for k in range(len(RFC_grid[\"n_estimators\"])):\n",
    "                    ada = AdaBoostClassifier(base_estimator=RFC_grid[\"base_estimator\"][i], learning_rate=RFC_grid[\"learning_rate\"][l], n_estimators=RFC_grid['n_estimators'][k], random_state=1)\n",
    "                    ada.fit(X_train_std, y_train)\n",
    "                    score1 = ada.score(X_test_std, y_test)\n",
    "                    score2 = ada.score(X_train_std, y_train)\n",
    "                    dic[ada]=score1\n",
    "\n",
    "                    if score1>max_score:\n",
    "                        val=cross_val_score(estimator=ada,\n",
    "                                            X=X_train_std, y=y_train,\n",
    "                                            cv=3)\n",
    "                        val1=np.mean(val)\n",
    "                        print('params: %s, train: %3f, test: %3f, val: %3f' %(ada, score2, score1, val1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
